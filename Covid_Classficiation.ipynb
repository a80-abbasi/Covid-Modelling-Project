{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Loading Dataset:"
   ],
   "metadata": {
    "id": "mVnaaG1KooyN",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!git clone \"https://github.com/muhammedtalo/COVID-19.git\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s3GUv19Mmvzl",
    "outputId": "2f3a38fb-ac71-465a-ea4a-824a18de0302",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'COVID-19'...\n",
      "remote: Enumerating objects: 1237, done.\u001B[K\n",
      "remote: Counting objects: 100% (81/81), done.\u001B[K\n",
      "remote: Compressing objects: 100% (59/59), done.\u001B[K\n",
      "remote: Total 1237 (delta 27), reused 75 (delta 22), pack-reused 1156\u001B[K\n",
      "Receiving objects: 100% (1237/1237), 400.89 MiB | 41.99 MiB/s, done.\n",
      "Resolving deltas: 100% (29/29), done.\n",
      "Checking out files: 100% (1129/1129), done.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!mv \"COVID-19/X-Ray Image DataSet\" \".\""
   ],
   "metadata": {
    "id": "98hjBuBSnQ6k",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!ls"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9KMTFnwjn_Ey",
    "outputId": "93cae3de-f1f5-4c67-c682-021dae46f47c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " COVID-19   sample_data  'X-Ray Image DataSet'\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading pretrained weights:"
   ],
   "metadata": {
    "id": "EZ1Nb8G4or2T",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!git clone \"https://github.com/arnoweng/CheXNet.git\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m9xk6jc7ou4T",
    "outputId": "26e892ca-d6cd-47b4-a0ce-27c1d870a060",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'CheXNet'...\n",
      "remote: Enumerating objects: 62, done.\u001B[K\n",
      "remote: Counting objects: 100% (10/10), done.\u001B[K\n",
      "remote: Compressing objects: 100% (5/5), done.\u001B[K\n",
      "remote: Total 62 (delta 6), reused 5 (delta 5), pack-reused 52\u001B[K\n",
      "Unpacking objects: 100% (62/62), done.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!mv \"./CheXNet/model.pth.tar\" \".\""
   ],
   "metadata": {
    "id": "XsG5zWdto8HT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!ls"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q1RLr4oXpKCq",
    "outputId": "af4d79ee-4e6b-42f4-bb0b-444e8bb4bb50",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " CheXNet   COVID-19   model.pth.tar   sample_data  'X-Ray Image DataSet'\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DATASET_ROOT = 'X-Ray Image DataSet'\n",
    "CKPT_PATH = 'model.pth.tar'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importing from libraries:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "from torchvision.transforms import functional as TF\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from torchvision.datasets import VOCSegmentation\n",
    "from torchvision import models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Imports from my code:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setting seed:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(24)\n",
    "np.random.seed(24)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Class for loading pretrained model:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DenseNet121(nn.Module):\n",
    "    def __init__(self, num_classes, weights=True):\n",
    "        super(DenseNet121, self).__init__()\n",
    "        self.densenet121 = torchvision.models.densenet121()\n",
    "        num_features = self.densenet121.classifier.in_features\n",
    "        if weights:\n",
    "            self.densenet121.classifier = nn.Sequential(\n",
    "                nn.Linear(num_features, 14)\n",
    "            )\n",
    "            load_weights(self)\n",
    "        self.densenet121.classifier = nn.Linear(num_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.densenet121(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def load_weights(model, device='cpu'):\n",
    "    # Code modified from torchvision densenet source for loading from pre .4 densenet weights.\n",
    "    checkpoint = torch.load(CKPT_PATH, map_location=torch.device(device))\n",
    "    state_dict = checkpoint['state_dict']\n",
    "    remove_data_parallel = True  # Change if you don't want to use nn.DataParallel(model)\n",
    "\n",
    "    pattern = re.compile(\n",
    "        r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
    "    for key in list(state_dict.keys()):\n",
    "        match = pattern.match(key)\n",
    "        new_key = match.group(1) + match.group(2) if match else key\n",
    "        new_key = new_key[7:] if remove_data_parallel else new_key\n",
    "        state_dict[new_key] = state_dict[key]\n",
    "        # Delete old key only if modified.\n",
    "        if match or remove_data_parallel:\n",
    "            del state_dict[key]\n",
    "\n",
    "    model.load_state_dict(state_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading pretrained model:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = DenseNet121(3).to(device)\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dataset for loading images:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class CovidDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, shuffle=True):\n",
    "        if not isinstance(root, Path):\n",
    "            root = Path(root)\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        data = []\n",
    "        for y in os.listdir(self.root):\n",
    "            for x in os.listdir(os.path.join(self.root, y)):\n",
    "                data.append({'image': x, 'label': y})\n",
    "        self.dataframe = pd.DataFrame(data)\n",
    "        self.label_names, labels = np.unique(self.dataframe['label'], return_inverse=True)\n",
    "        self.dataframe['label'] = labels\n",
    "        self.label_counts = self.dataframe['label'].value_counts()\n",
    "        self.label_weights = len(self.dataframe) / self.label_counts\n",
    "        self.label_weights = self.label_weights / self.label_weights.sum()\n",
    "        if shuffle:\n",
    "            self.dataframe = self.dataframe.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = self.dataframe.loc[index]\n",
    "        image_name, label = item['image'], item['label']\n",
    "        label_name = self.label_names[label]\n",
    "        image_path = self.root / label_name / image_name\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "normalize = T.Normalize([0.485, 0.456, 0.406],\n",
    "                        [0.229, 0.224, 0.225])\n",
    "\n",
    "# dataset = CovidDataset(DATASET_ROOT, transform=T.Compose([\n",
    "#                                     T.Resize(256),\n",
    "#                                     T.TenCrop(224),\n",
    "#                                     T.Lambda\n",
    "#                                     (lambda crops: torch.stack([T.ToTensor()(crop) for crop in crops])),\n",
    "#                                     T.Lambda\n",
    "#                                     (lambda crops: torch.stack([normalize(crop) for crop in crops]))\n",
    "#                                 ]))\n",
    "dataset = CovidDataset(DATASET_ROOT,\n",
    "                       transform=T.Compose([\n",
    "                           T.Resize((256, 256)),\n",
    "                           T.ToTensor(),\n",
    "                           normalize\n",
    "                       ]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset.label_weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset[0][0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model(dataset[0][0].to(device).unsqueeze(0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dataloaders:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# splitting train and test sets\n",
    "voc_len = len(dataset)\n",
    "train_len = int(0.8 * voc_len)\n",
    "test_len = voc_len - train_len\n",
    "train_set, test_set = random_split(dataset, [train_len, test_len])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# splitting train and val sets\n",
    "train_len = int(0.8 * len(train_set))\n",
    "val_len = len(train_set) - train_len\n",
    "train_set, val_set = random_split(train_set, [train_len, val_len])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, 64, shuffle=True)\n",
    "val_loader = DataLoader(val_set, 64, shuffle=True)\n",
    "test_loader = DataLoader(test_set, 64, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training functions:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time, tqdm\n",
    "\n",
    "\n",
    "def train(model, train_loader, criterion, optimizer, epoch):\n",
    "    train_loss = 0\n",
    "    N_train = len(train_loader.dataset)\n",
    "\n",
    "    model.train()\n",
    "    with tqdm.tqdm(enumerate(train_loader), total=len(train_loader)) as pbar:\n",
    "        for i, (x, y) in pbar:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            p = model(x)\n",
    "\n",
    "            loss = criterion(p, y)\n",
    "            train_loss += loss.item() * len(x)\n",
    "\n",
    "            pbar.set_description(f'Epoch:{epoch}, Train Loss: {train_loss / N_train:.3e}')\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    train_loss /= N_train\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def validate(model, val_loader, criterion, epoch=0, metrics=None):\n",
    "    val_loss = 0\n",
    "    N_val = len(val_loader.dataset)\n",
    "    Y = []\n",
    "    Y_pred = []\n",
    "    model.eval()\n",
    "    with torch.no_grad(), tqdm.tqdm(enumerate(val_loader), total=len(val_loader)) as pbar:\n",
    "        for i, (x, y) in pbar:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            p = model(x)\n",
    "            y_pred = p.argmax(dim=-1)\n",
    "            loss = criterion(p, y)\n",
    "            val_loss += loss.item() * len(x)\n",
    "\n",
    "            pbar.set_description(f'Epoch:{epoch}, Val Loss: {val_loss / N_val:.3e}')\n",
    "            Y.append(y.cpu().numpy())\n",
    "            Y_pred.append(y_pred.cpu().numpy())\n",
    "    Y = np.concatenate(Y)\n",
    "    Y_pred = np.concatenate(Y_pred)\n",
    "    val_loss /= N_val\n",
    "    if metrics is not None:\n",
    "        return {metric: metric_func(Y, Y_pred) for metric, metric_func in metrics.items()}\n",
    "    return val_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_losses, val_losses = list(), list()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_model(model, criterion, dataloaders, optimizer, num_epochs, model_name='pytorch_model'):\n",
    "    val = len(dataloaders) == 2\n",
    "    if val:\n",
    "        train_loader, val_loader = dataloaders\n",
    "    else:\n",
    "        train_loader, = dataloaders\n",
    "\n",
    "    val_loss_min = np.inf\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train(model, train_loader, criterion, optimizer, epoch)\n",
    "        train_losses.append(train_loss)\n",
    "        if val:\n",
    "            val_loss = validate(model, val_loader, criterion, epoch)\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "            if val_loss <= val_loss_min:\n",
    "                torch.save(model.state_dict(), f'{model_name}.pt')\n",
    "                val_loss_min = val_loss\n",
    "        print('\\n', '---' * 20)\n",
    "    if val:\n",
    "        # load best model during different epochs\n",
    "        model.load_state_dict(torch.load(f'{model_name}.pt'))\n",
    "        plt.plot(val_losses, label='val')\n",
    "\n",
    "    plt.plot(train_losses, label='train')\n",
    "    plt.legend()\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Freezing pretrained layers:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.densenet121.classifier.parameters():\n",
    "    param.requires_grad = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Learning Config:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor(dataset.label_weights.sort_index().tolist())).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Overfitting on a small dataset:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "small_len = int(0.1 * len(train_set))\n",
    "print(small_len)\n",
    "other_len = len(train_set) - small_len\n",
    "_, small_set = random_split(train_set, [other_len, small_len])\n",
    "small_loader = DataLoader(small_set, 64, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "train_model(model, criterion, [small_loader], optimizer, 30);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "validate(model, small_loader, criterion, metrics={'accuracy': lambda y1, y2: (y1==y2).mean()})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tuning hyper-parameters:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# todo!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training model:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# reinitialize model and losses\n",
    "train_losses, val_losses = list(), list()\n",
    "model = DenseNet121(3).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lr = 1e-6\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "model = train_model(model, criterion, [train_loader, val_loader], optimizer, 30, 'covid-classification');"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "average_policy = 'macro'\n",
    "metrics = {'accuracy': accuracy_score, 'precision': lambda y1, y2: precision_score(y1, y2, average=average_policy),\n",
    "           'recall': lambda y1, y2: recall_score(y1, y2, average=average_policy),\n",
    "           'f1': lambda y1, y2: f1_score(y1, y2, average=average_policy)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "validate(model, test_loader, criterion, metrics=metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('covid-classification.pt') "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "average_policy = 'macro'\n",
    "metrics = {'accuracy': accuracy_score, 'precision': lambda y1, y2: precision_score(y1, y2, average=average_policy),\n",
    "           'recall': lambda y1, y2: recall_score(y1, y2, average=average_policy),\n",
    "           'f1': lambda y1, y2: f1_score(y1, y2, average=average_policy)}"
   ],
   "metadata": {
    "id": "DgIAUjEitbJG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 58,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "validate(model, test_loader, criterion, metrics=metrics)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vZztlzk4yEn7",
    "outputId": "fbd52e6a-fb11-4bdf-af37-78d0c6d3d3f2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 59,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch:0, Val Loss: 4.035e-01: 100%|██████████| 4/4 [00:06<00:00,  1.59s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "-------------------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'accuracy': 0.8755555555555555,\n",
       " 'precision': 0.9053116195973337,\n",
       " 'recall': 0.8972110732285089,\n",
       " 'f1': 0.9008532557646274}"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import files\n",
    "files.download('covid-classification.pt') "
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "AETOkCA08Aag",
    "outputId": "b5154ae3-dc01-4b06-e88d-6dabf0644464"
   },
   "execution_count": 60,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": [
       "download(\"download_ae796cd8-69be-4ca6-a837-11d1b2e12b2e\", \"covid-classification.pt\", 28445267)"
      ]
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "_PQPa2uFBCbr"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}