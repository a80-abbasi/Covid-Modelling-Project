{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mVnaaG1KooyN",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Loading Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s3GUv19Mmvzl",
    "outputId": "2f3a38fb-ac71-465a-ea4a-824a18de0302",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !git clone \"https://github.com/muhammedtalo/COVID-19.git\"\n",
    "# !mv \"COVID-19/X-Ray Image DataSet\" \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# This mounts your Google Drive to the Colab VM.\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AlexNet  GoogleNet  Pneumonia\t      ResNet50_dropout\tVGG16_v2\n",
      "covid\t normal     ResNet18_dropout  VGG16\n"
     ]
    }
   ],
   "source": [
    "!ls '/content/drive/MyDrive/COVID Project - Summer 2022/Colab_Notebooks'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "our_covid_dataset = '/content/drive/MyDrive/COVID Project - Summer 2022/Colab_Notebooks/covid'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Kaggle Dataset:\n",
    "Dataset link is: `https://drive.google.com/file/d/1bum9Sehb3AzUMHLhBMuowPKyr_PCrB3a/view?usp=sharing`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install gdown\n",
    "!gdown 1bum9Sehb3AzUMHLhBMuowPKyr_PCrB3a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!unzip COVID-19_Radiography_Dataset.zip"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "kaggle_dataset = Path('COVID-19_Radiography_Dataset')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "# add other sources of images here:\n",
    "data = {'covid': [our_covid_dataset, kaggle_dataset / \"COVID/images\"],\n",
    "        'normal': [kaggle_dataset / \"Normal/images\"],\n",
    "        'pneumonia': [kaggle_dataset / \"Viral Pneumonia/images\"], }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dataset/covid\n",
      "dataset/normal\n",
      "dataset/pneumonia\n"
     ]
    }
   ],
   "source": [
    "!rm -r dataset\n",
    "\n",
    "# create gathered dataset\n",
    "import os\n",
    "from distutils.dir_util import copy_tree\n",
    "\n",
    "DATASET_ROOT = Path('dataset')\n",
    "os.mkdir(DATASET_ROOT)\n",
    "for image_class, image_sources in data.items():\n",
    "    class_path = DATASET_ROOT / image_class\n",
    "    print(str(class_path))\n",
    "    os.mkdir(class_path)\n",
    "    if not isinstance(image_sources, list):\n",
    "        image_sources = [image_sources]\n",
    "    for source in image_sources:\n",
    "        copy_tree(source, str(class_path))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading pretrained model:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!git clone \"https://github.com/arnoweng/CheXNet.git\"\n",
    "!mv \"./CheXNet/model.pth.tar\" \".\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Twjv-sqkpOfK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# DATASET_ROOT = 'dataset'\n",
    "PRETRAINED_MODEL = 'model.pth.tar'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "cAOHp7gJmt_p",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Importing from libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f_ywkSuL_bfL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "from torchvision.transforms import functional as TF\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from torchvision.datasets import VOCSegmentation\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "is-fG1Esmt_v",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Imports from my code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-1wbjDZbmt_v",
    "outputId": "5fa89756-4553-48b1-8380-9cd2fe4babf9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "% load_ext autoreload\n",
    "% autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "psPtcNwQmt_w",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Setting seed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4vsNHPlBBL-3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(24)\n",
    "np.random.seed(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-19Hanbmt_x",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "nZNJtgftmt_y",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SBRzn70jmt_y",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DenseNet121(nn.Module):\n",
    "    def __init__(self, num_classes, weights=True):\n",
    "        super(DenseNet121, self).__init__()\n",
    "        self.densenet121 = torchvision.models.densenet121()\n",
    "        num_features = self.densenet121.classifier.in_features\n",
    "        if weights:\n",
    "            self.densenet121.classifier = nn.Sequential(\n",
    "                nn.Linear(num_features, 14)\n",
    "            )\n",
    "            load_weights(self)\n",
    "        self.densenet121.classifier = nn.Linear(num_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.densenet121(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def load_weights(model, device='cpu'):\n",
    "    # Code modified from torchvision densenet source for loading from pre .4 densenet weights.\n",
    "    checkpoint = torch.load(PRETRAINED_MODEL, map_location=torch.device(device))\n",
    "    state_dict = checkpoint['state_dict']\n",
    "    remove_data_parallel = True  # Change if you don't want to use nn.DataParallel(model)\n",
    "\n",
    "    pattern = re.compile(\n",
    "        r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
    "    for key in list(state_dict.keys()):\n",
    "        match = pattern.match(key)\n",
    "        new_key = match.group(1) + match.group(2) if match else key\n",
    "        new_key = new_key[7:] if remove_data_parallel else new_key\n",
    "        state_dict[new_key] = state_dict[key]\n",
    "        # Delete old key only if modified.\n",
    "        if match or remove_data_parallel:\n",
    "            del state_dict[key]\n",
    "\n",
    "    model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "KIQ6CljEmt_z",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Loading pretrained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C09CteYFmt_0",
    "outputId": "2d2d1c09-8235-4e1e-a45c-bb53ca9c9688",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = DenseNet121(3).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "uLrd96Axmt_1",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Dataset for loading images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mWbxLB9Dmt_1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CovidDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, shuffle=True, balanced=True):\n",
    "        if not isinstance(root, Path):\n",
    "            root = Path(root)\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        data = []\n",
    "        for y in os.listdir(self.root):\n",
    "            for x in os.listdir(os.path.join(self.root, y)):\n",
    "                data.append({'image': x, 'label': y})\n",
    "        self.dataframe = pd.DataFrame(data)\n",
    "        self.label_names, labels = np.unique(self.dataframe['label'], return_inverse=True)\n",
    "        self.dataframe['label'] = labels\n",
    "        self.original_label_counts = self.dataframe['label'].value_counts()\n",
    "        if balanced:\n",
    "            g = self.dataframe.groupby('class')\n",
    "            self.dataframe = g.apply(lambda class_df: class_df.sample(g.size().min()).reset_index(drop=True))\n",
    "        if shuffle:\n",
    "            self.dataframe = self.dataframe.sample(frac=1).reset_index(drop=True)\n",
    "        self.label_counts = self.dataframe['label'].value_counts()\n",
    "        self.label_weights = len(self.dataframe) / self.label_counts\n",
    "        self.label_weights = self.label_weights / self.label_weights.sum()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = self.dataframe.loc[index]\n",
    "        image_name, label = item['image'], item['label']\n",
    "        label_name = self.label_names[label]\n",
    "        image_path = self.root / label_name / image_name\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uYtL_1CEmt_2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "normalize = T.Normalize([0.485, 0.456, 0.406],\n",
    "                        [0.229, 0.224, 0.225])\n",
    "\n",
    "# dataset = CovidDataset(DATASET_ROOT, transform=T.Compose([\n",
    "#                                     T.Resize(256),\n",
    "#                                     T.TenCrop(224),\n",
    "#                                     T.Lambda\n",
    "#                                     (lambda crops: torch.stack([T.ToTensor()(crop) for crop in crops])),\n",
    "#                                     T.Lambda\n",
    "#                                     (lambda crops: torch.stack([normalize(crop) for crop in crops]))\n",
    "#                                 ]))\n",
    "dataset = CovidDataset(DATASET_ROOT,\n",
    "                       transform=T.Compose([\n",
    "                           T.Resize((256, 256)),\n",
    "                           T.ToTensor(),\n",
    "                           normalize\n",
    "                       ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u_qqHmVi5bNd",
    "outputId": "c1a36f89-53e7-460e-eb96-341b6702c9f0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset.label_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VNXvOCger48r",
    "outputId": "a1f0f5ad-ea77-4015-ddd2-eb4b57524af1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iZOzxny9suKL",
    "outputId": "81132026-1d4e-4653-f0ce-c73c58e98af1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model(dataset[0][0].to(device).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "aDn08H9Nmt_2",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Dataloaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xcsDe4m2mt_2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# splitting train and test sets\n",
    "voc_len = len(dataset)\n",
    "train_len = int(0.8 * voc_len)\n",
    "test_len = voc_len - train_len\n",
    "train_set, test_set = random_split(dataset, [train_len, test_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CiE1edLE5bNh",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# splitting train and val sets\n",
    "train_len = int(0.8 * len(train_set))\n",
    "val_len = len(train_set) - train_len\n",
    "train_set, val_set = random_split(train_set, [train_len, val_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oXW8x8TJmt_2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, 64, shuffle=True)\n",
    "val_loader = DataLoader(val_set, 64, shuffle=True)\n",
    "test_loader = DataLoader(test_set, 64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "LWOuPnL35bNi",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Training functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m3l4cK-_KuvG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time, tqdm\n",
    "\n",
    "\n",
    "def train(model, train_loader, criterion, optimizer, epoch):\n",
    "    train_loss = 0\n",
    "    N_train = len(train_loader.dataset)\n",
    "\n",
    "    model.train()\n",
    "    with tqdm.tqdm(enumerate(train_loader), total=len(train_loader)) as pbar:\n",
    "        for i, (x, y) in pbar:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            p = model(x)\n",
    "\n",
    "            loss = criterion(p, y)\n",
    "            train_loss += loss.item() * len(x)\n",
    "\n",
    "            pbar.set_description(f'Epoch:{epoch}, Train Loss: {train_loss / N_train:.3e}')\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    train_loss /= N_train\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def validate(model, val_loader, criterion, epoch=0, metrics=None):\n",
    "    val_loss = 0\n",
    "    N_val = len(val_loader.dataset)\n",
    "    Y = []\n",
    "    Y_pred = []\n",
    "    model.eval()\n",
    "    with torch.no_grad(), tqdm.tqdm(enumerate(val_loader), total=len(val_loader)) as pbar:\n",
    "        for i, (x, y) in pbar:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            p = model(x)\n",
    "            y_pred = p.argmax(dim=-1)\n",
    "            loss = criterion(p, y)\n",
    "            val_loss += loss.item() * len(x)\n",
    "\n",
    "            pbar.set_description(f'Epoch:{epoch}, Val Loss: {val_loss / N_val:.3e}')\n",
    "            Y.append(y.cpu().numpy())\n",
    "            Y_pred.append(y_pred.cpu().numpy())\n",
    "    Y = np.concatenate(Y)\n",
    "    Y_pred = np.concatenate(Y_pred)\n",
    "    val_loss /= N_val\n",
    "    result = {'loss': val_loss}\n",
    "    if metrics is not None:\n",
    "        result.update({metric: metric_func(Y, Y_pred) for metric, metric_func in metrics.items()})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yFdNnS7Zk1oy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_losses, val_losses = list(), list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KmeKLMBIMsSF",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, dataloaders, optimizer, num_epochs, model_name='pytorch_model', validation_metrics=None):\n",
    "    val = len(dataloaders) == 2\n",
    "    if val:\n",
    "        train_loader, val_loader = dataloaders\n",
    "    else:\n",
    "        train_loader, = dataloaders\n",
    "\n",
    "    if validation_metrics is None:\n",
    "        validation_metrics = dict()\n",
    "\n",
    "    metrics_history = {metric: [] for metric in validation_metrics}\n",
    "    val_loss_min = np.inf\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train(model, train_loader, criterion, optimizer, epoch)\n",
    "        train_losses.append(train_loss)\n",
    "        if val:\n",
    "            result = validate(model, val_loader, criterion, epoch, metrics=validation_metrics)\n",
    "            val_loss = result['loss']\n",
    "            val_losses.append(val_loss)\n",
    "            for metric, metric_history in metrics_history:\n",
    "                metric_history.append(result[metric])\n",
    "\n",
    "            if val_loss <= val_loss_min:\n",
    "                torch.save(model.state_dict(), f'{model_name}.pt')\n",
    "                val_loss_min = val_loss\n",
    "        print('\\n', '---' * 20)\n",
    "    plt.plot(train_losses, label='train')\n",
    "    if val:\n",
    "        # load best model during different epochs\n",
    "        model.load_state_dict(torch.load(f'{model_name}.pt'))\n",
    "        plt.plot(val_losses, label='val')\n",
    "        if len(metrics_history):\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            for metric, metric_history in metrics_history:\n",
    "                plt.plot(metric_history, label=metric)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "PpcRjwfl5bNn",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Freezing pretrained layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nwDNVJS4mt_4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.densenet121.classifier.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "XChGUM0a5bNo",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Learning Config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hDpzasmdmt_4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor(dataset.label_weights.sort_index().tolist())).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "-KTL9VPA5bNp",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Overfitting on a small dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8iufSc0B5bNq",
    "outputId": "c22efcc8-ad63-4081-f6d8-3a17a4e42a33",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "small_len = int(0.1 * len(train_set))\n",
    "print(small_len)\n",
    "other_len = len(train_set) - small_len\n",
    "_, small_set = random_split(train_set, [other_len, small_len])\n",
    "small_loader = DataLoader(small_set, 64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 786
    },
    "id": "l7XZHtw95bNq",
    "outputId": "be3f8731-3764-4716-fa13-0014d3fe7e28",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "train_model(model, criterion, [small_loader], optimizer, 30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RTJUhdvy7Jja",
    "outputId": "7ca47f52-c980-467b-c37d-b5351acb7dad",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "validate(model, small_loader, criterion, metrics={'accuracy': lambda y1, y2: (y1 == y2).mean()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "AJFneV-Z5bNr",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Tuning hyper-parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TKk8jiN45bNr",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# todo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "KLHCZL6D5bNr",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Training model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gEfHhJrC7duW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# reinitialize model and losses\n",
    "train_losses, val_losses = list(), list()\n",
    "model = DenseNet121(3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sX25ESEW5bNs",
    "outputId": "7866dcd8-7bfc-4342-d852-599430660de8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lr = 1e-6\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "model = train_model(model, criterion, [train_loader, val_loader], optimizer, 30, 'covid-classification');"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DgIAUjEitbJG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "average_policy = 'macro'\n",
    "metrics = {'accuracy': accuracy_score, 'precision': lambda y1, y2: precision_score(y1, y2, average=average_policy),\n",
    "           'recall': lambda y1, y2: recall_score(y1, y2, average=average_policy),\n",
    "           'f1': lambda y1, y2: f1_score(y1, y2, average=average_policy)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vZztlzk4yEn7",
    "outputId": "fbd52e6a-fb11-4bdf-af37-78d0c6d3d3f2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "validate(model, test_loader, criterion, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "AETOkCA08Aag",
    "outputId": "b5154ae3-dc01-4b06-e88d-6dabf0644464",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "files.download('covid-classification.pt')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}